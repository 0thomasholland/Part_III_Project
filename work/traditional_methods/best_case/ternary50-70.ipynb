{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7829294c",
   "metadata": {},
   "source": [
    "# Ice Melt Contribution Ternary Plot Analysis - HD\n",
    "\n",
    "Motivation: Appears the range from 50-70 has lowest combined error, so investigating this range in higher resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e04e90",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a403704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyslfp import FingerPrint, IceModel\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from Part_III_Project import (\n",
    "    sea_surface_height_change,\n",
    "    plot_ternary_heatmap,\n",
    "    plot_ternary_heatmap_subplots,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8578cd",
   "metadata": {},
   "source": [
    "## Variable setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575122e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FingerPrint(lmax=256)\n",
    "fp.set_state_from_ice_ng(version=IceModel.ICE7G, date=0.0)\n",
    "\n",
    "\n",
    "sat_data_range = np.linspace(50, 70, 9)  # in degrees\n",
    "plot_resolution = 100  # how many points along 0-100% axis\n",
    "\n",
    "print(\"sat_data_range:\", sat_data_range)\n",
    "\n",
    "error_output = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04903e09",
   "metadata": {},
   "source": [
    "## Calculating Sea Surface Height Change Errors\n",
    "\n",
    "### Non-parallel version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ade1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for segment in sat_data_range:\n",
    "#     for west_contribution in np.arange(0, 1, 1/plot_resolution):\n",
    "#         for east_contribution in tqdm(np.arange(0, 1 - west_contribution, 1/plot_resolution)):\n",
    "#             green_contribution = 1 - west_contribution - east_contribution\n",
    "#             # print(f\"Greenland: {green_contribution}, West Antarctica: {west_contribution}, East Antarctica: {east_contribution}\")\n",
    "\n",
    "#             direct_load = (\n",
    "#                 green_contribution * fp.greenland_load()\n",
    "#                 + west_contribution * fp.west_antarctic_load()\n",
    "#                 + east_contribution * fp.east_antarctic_load()\n",
    "#             )\n",
    "\n",
    "#             (\n",
    "#                 sea_level_change,\n",
    "#                 displacement,\n",
    "#                 gravitational_potential_change,\n",
    "#                 angular_velocity_change,\n",
    "#             ) = fp(direct_load=direct_load)\n",
    "\n",
    "#             sea_surface_height_change_result = sea_surface_height_change(\n",
    "#                 fp, sea_level_change, displacement, angular_velocity_change\n",
    "#             )\n",
    "#             mean_sea_level_change = fp.mean_sea_level_change(direct_load)\n",
    "#             altimetry_projection = fp.altimetry_projection(\n",
    "#                 latitude_min=-segment, latitude_max=segment, value=0\n",
    "#             )\n",
    "#             altimetry_projection_integral = fp.integrate(altimetry_projection)\n",
    "#             altimetry_weighting_function = (\n",
    "#                 altimetry_projection / altimetry_projection_integral\n",
    "#             )\n",
    "\n",
    "#             mean_sea_level_change_estimate = fp.integrate(\n",
    "#                 altimetry_weighting_function * sea_surface_height_change_result\n",
    "#             )\n",
    "\n",
    "#             error = (\n",
    "#                 100\n",
    "#                 * np.abs(mean_sea_level_change_estimate - mean_sea_level_change)\n",
    "#                 / np.abs(mean_sea_level_change)\n",
    "#             )\n",
    "\n",
    "#             error_output = pd.concat(\n",
    "#                 [\n",
    "#                     error_output,\n",
    "#                     pd.DataFrame(\n",
    "#                         {\n",
    "#                             \"segment\": [segment],\n",
    "#                             \"greenland_contribution\": [green_contribution],\n",
    "#                             \"west_antarctic_contribution\": [west_contribution],\n",
    "#                             \"east_antarctic_contribution\": [east_contribution],\n",
    "#                             \"error\": [error],\n",
    "#                         }\n",
    "#                     ),\n",
    "#                 ],\n",
    "#                 ignore_index=True,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080b168",
   "metadata": {},
   "source": [
    "### Parallel version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d83663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_for_combination(segments, west_contribution, east_contribution, fp):\n",
    "    green_contribution = 1 - west_contribution - east_contribution\n",
    "\n",
    "    direct_load = (\n",
    "        green_contribution * fp.greenland_load()\n",
    "        + west_contribution * fp.west_antarctic_load()\n",
    "        + east_contribution * fp.east_antarctic_load()\n",
    "    )\n",
    "\n",
    "    (\n",
    "        sea_level_change,\n",
    "        displacement,\n",
    "        gravitational_potential_change,\n",
    "        angular_velocity_change,\n",
    "    ) = fp(direct_load=direct_load)\n",
    "\n",
    "    sea_surface_height_change_result = sea_surface_height_change(\n",
    "        fp, sea_level_change, displacement, angular_velocity_change\n",
    "    )\n",
    "    mean_sea_level_change = fp.mean_sea_level_change(direct_load)\n",
    "\n",
    "    results = []\n",
    "    for segment in segments:\n",
    "        altimetry_projection = fp.altimetry_projection(\n",
    "            latitude_min=-segment, latitude_max=segment, value=0\n",
    "        )\n",
    "        altimetry_projection_integral = fp.integrate(altimetry_projection)\n",
    "        altimetry_weighting_function = (\n",
    "            altimetry_projection / altimetry_projection_integral\n",
    "        )\n",
    "\n",
    "        mean_sea_level_change_estimate = fp.integrate(\n",
    "            altimetry_weighting_function * sea_surface_height_change_result\n",
    "        )\n",
    "\n",
    "        error = (\n",
    "            100\n",
    "            * np.abs(mean_sea_level_change_estimate - mean_sea_level_change)\n",
    "            / np.abs(mean_sea_level_change)\n",
    "        )\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"segment\": segment,\n",
    "                \"greenland_contribution\": green_contribution,\n",
    "                \"west_antarctic_contribution\": west_contribution,\n",
    "                \"east_antarctic_contribution\": east_contribution,\n",
    "                \"error\": error,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Generate all combinations\n",
    "tasks = []\n",
    "for west_contribution in np.linspace(0, 1, plot_resolution + 1):\n",
    "    for east_contribution in np.linspace(0, 1 - west_contribution, plot_resolution + 1):\n",
    "        tasks.append((sat_data_range, west_contribution, east_contribution))\n",
    "\n",
    "# Run in parallel\n",
    "results = Parallel(n_jobs=-1, verbose=4, batch_size=\"auto\")(\n",
    "    delayed(compute_error_for_combination)(seg, west, east, fp)\n",
    "    for seg, west, east in tasks\n",
    ")\n",
    "\n",
    "# Flatten the list of lists into a single list of dictionaries\n",
    "flattened_results = [item for sublist in results for item in sublist]\n",
    "\n",
    "error_output = pd.DataFrame(flattened_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6016186c",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5edf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_output.to_csv(\"ternary_50-70_sea_surface_height_error.csv\")\n",
    "error_output = pd.read_csv(\"ternary_50-70_sea_surface_height_error.csv\")\n",
    "\n",
    "print(error_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c56f8e",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Ternary plotting methods to visualise the error in sea surface height change estimates based on varying contributions from three ice melt sources: Greenland, West Antarctica, and East Antarctica.\n",
    "\n",
    "Now in the src/Part_III_Project/plotting_methods.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfcc6f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# def plot_ternary_heatmap_subplots(\n",
    "#     df, segment_list, sources, labels, ncols=3, figsize_per_plot=(6, 5)\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Plot multiple ternary heatmaps as subplots using mpltern\n",
    "\n",
    "#     Parameters:\n",
    "#     df: DataFrame with columns ['segment', 'error', 'contribution'...]\n",
    "#     segment_list: List of segment values to plot\n",
    "#     sources: List of column names for the three contributions\n",
    "#     labels: List of labels for the three contributions\n",
    "#     ncols: Number of columns in the subplot grid\n",
    "#     figsize_per_plot: Tuple of (width, height) for each individual plot\n",
    "#     \"\"\"\n",
    "\n",
    "#     n_segments = len(segment_list)\n",
    "#     nrows = int(np.ceil(n_segments / ncols))\n",
    "\n",
    "#     # Create figure\n",
    "#     fig = plt.figure(figsize=(figsize_per_plot[0] * ncols, figsize_per_plot[1] * nrows))\n",
    "\n",
    "#     # Get global min/max error for consistent color scale\n",
    "#     global_vmin = df[df[\"segment\"].isin(segment_list)][\"error\"].min()\n",
    "#     global_vmax = df[df[\"segment\"].isin(segment_list)][\"error\"].max()\n",
    "\n",
    "#     for idx, segment_name in enumerate(segment_list):\n",
    "#         # Create ternary subplot\n",
    "#         ax = fig.add_subplot(nrows, ncols, idx + 1, projection=\"ternary\")\n",
    "\n",
    "#         # Filter data for the specific segment\n",
    "#         segment_data = df[df[\"segment\"] == segment_name].copy()\n",
    "\n",
    "#         if len(segment_data) == 0:\n",
    "#             ax.text(\n",
    "#                 0.5,\n",
    "#                 0.5,\n",
    "#                 f\"No data for segment {segment_name}\",\n",
    "#                 ha=\"center\",\n",
    "#                 va=\"center\",\n",
    "#                 transform=ax.transAxes,\n",
    "#             )\n",
    "#             continue\n",
    "\n",
    "#         # Extract the three components and error values\n",
    "#         top = segment_data[f\"{sources[0]}\"].values\n",
    "#         left = segment_data[f\"{sources[1]}\"].values\n",
    "#         right = segment_data[f\"{sources[2]}\"].values\n",
    "#         errors = segment_data[\"error\"].values\n",
    "\n",
    "#         # Plot using tripcolor with gouraud shading for smooth interpolation\n",
    "#         cs = ax.tripcolor(\n",
    "#             top,\n",
    "#             left,\n",
    "#             right,\n",
    "#             errors,\n",
    "#             shading=\"gouraud\",\n",
    "#             cmap=\"RdYlBu_r\",\n",
    "#             vmin=global_vmin,\n",
    "#             vmax=global_vmax,\n",
    "#             rasterized=True,\n",
    "#         )\n",
    "\n",
    "#         # Set axis labels\n",
    "#         ax.set_tlabel(labels[0], fontsize=10, fontweight=\"bold\")\n",
    "#         ax.set_llabel(labels[1], fontsize=10, fontweight=\"bold\")\n",
    "#         ax.set_rlabel(labels[2], fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "#         ax.taxis.set_label_position(\"corner\")\n",
    "#         ax.laxis.set_label_position(\"corner\")\n",
    "#         ax.raxis.set_label_position(\"corner\")\n",
    "\n",
    "#         # Set title\n",
    "#         ax.set_title(\n",
    "#             f\"Satellite Segment ±{segment_name}°\",\n",
    "#             fontsize=11,\n",
    "#             fontweight=\"bold\",\n",
    "#             pad=15,\n",
    "#         )\n",
    "\n",
    "#         # Add individual colorbar for this subplot\n",
    "#         cax = ax.inset_axes([1.05, 0.1, 0.05, 0.8], transform=ax.transAxes)\n",
    "#         colorbar = fig.colorbar(cs, cax=cax)\n",
    "#         colorbar.set_label(\"Error\", rotation=270, va=\"baseline\", fontsize=9)\n",
    "\n",
    "#     plt.suptitle(\n",
    "#         \"Sea Level Rise Approximation Error Across Satellite Segments\",\n",
    "#         fontsize=16,\n",
    "#         fontweight=\"bold\",\n",
    "#         y=0.98,\n",
    "#     )\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     print_statement = \"Max error across all segments: {:.2f}; Min error across all segments: {:.2f}\".format(\n",
    "#         global_vmax, global_vmin\n",
    "#     )\n",
    "#     return fig, print_statement\n",
    "\n",
    "\n",
    "# def plot_ternary_heatmap(\n",
    "#     df: pd.DataFrame, segment_name: float, sources: list, labels: list\n",
    "# ) -> tuple:\n",
    "#     \"\"\"\n",
    "#     Plot a single ternary heatmap using mpltern\n",
    "\n",
    "#     Parameters:\n",
    "#     df: DataFrame with columns ['segment', 'error','contribution'...]\n",
    "#     segment_name: The segment to filter and plot\n",
    "#     sources: List of column names for the three contributions\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Filter data for the specific segment\n",
    "#     segment_data = df[df[\"segment\"] == segment_name].copy()\n",
    "\n",
    "#     if len(segment_data) == 0:\n",
    "#         print(f\"No data found for segment: {segment_name}\")\n",
    "#         return\n",
    "\n",
    "#     # Extract the three components and error values\n",
    "#     top = segment_data[f\"{sources[0]}\"].values\n",
    "#     left = segment_data[f\"{sources[1]}\"].values\n",
    "#     right = segment_data[f\"{sources[2]}\"].values\n",
    "#     errors = segment_data[\"error\"].values\n",
    "\n",
    "#     # Create figure with ternary projection\n",
    "#     fig = plt.figure(figsize=(10, 9))\n",
    "#     ax = fig.add_subplot(projection=\"ternary\")\n",
    "\n",
    "#     # Plot using tripcolor with gouraud shading for smooth interpolation\n",
    "#     cs = ax.tripcolor(\n",
    "#         top,\n",
    "#         left,\n",
    "#         right,\n",
    "#         errors,\n",
    "#         shading=\"gouraud\",\n",
    "#         cmap=\"RdYlBu_r\",\n",
    "#         rasterized=True,\n",
    "#         vmin=segment_data[\"error\"].min(),\n",
    "#         vmax=segment_data[\"error\"].max(),\n",
    "#     )\n",
    "\n",
    "#     # Set axis labels\n",
    "#     ax.set_tlabel(labels[0], fontsize=13, fontweight=\"bold\")\n",
    "#     ax.set_llabel(labels[1], fontsize=13, fontweight=\"bold\")\n",
    "#     ax.set_rlabel(labels[2], fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "#     ax.taxis.set_label_position(\"corner\")\n",
    "#     ax.laxis.set_label_position(\"corner\")\n",
    "#     ax.raxis.set_label_position(\"corner\")\n",
    "\n",
    "#     # Set title\n",
    "#     ax.set_title(\n",
    "#         f\"Sea Level Rise Approximation Error - Satellite Segment: ±{segment_name}°\",\n",
    "#         fontsize=14,\n",
    "#         fontweight=\"bold\",\n",
    "#         pad=20,\n",
    "#     )\n",
    "\n",
    "#     # Add colorbar\n",
    "#     cax = ax.inset_axes([1.05, 0.1, 0.05, 0.8], transform=ax.transAxes)\n",
    "#     colorbar = fig.colorbar(cs, cax=cax)\n",
    "#     colorbar.set_label(\"Error\", rotation=270, va=\"baseline\", fontsize=12)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ternary_heatmap(\n",
    "    error_output,\n",
    "    55,\n",
    "    [\n",
    "        \"greenland_contribution\",\n",
    "        \"west_antarctic_contribution\",\n",
    "        \"east_antarctic_contribution\",\n",
    "    ],\n",
    "    [\"Greenland\", \"West Antarctic\", \"East Antarctic\"],\n",
    ")\n",
    "plt.show()\n",
    "# fig.savefig(\"ternary_heatmap_segment_40.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24cdcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subplots for segments 10, 20, 30, 40, 50, 60, 70, 80, 90 with shared color scale\n",
    "\n",
    "fig, print_statement = plot_ternary_heatmap_subplots(\n",
    "    error_output,\n",
    "    segment_list=sat_data_range,\n",
    "    sources=[\n",
    "        \"greenland_contribution\",\n",
    "        \"west_antarctic_contribution\",\n",
    "        \"east_antarctic_contribution\",\n",
    "    ],\n",
    "    labels=[\"Greenland\", \"West Antarctic\", \"East Antarctic\"],\n",
    "    ncols=3,\n",
    "    uniform_color_scale=True,\n",
    ")\n",
    "\n",
    "print(print_statement)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subplots for segments 10, 20, 30, 40, 50, 60, 70, 80, 90 with unique color scale\n",
    "\n",
    "fig, print_statement = plot_ternary_heatmap_subplots(\n",
    "    error_output,\n",
    "    segment_list=sat_data_range,\n",
    "    sources=[\n",
    "        \"greenland_contribution\",\n",
    "        \"west_antarctic_contribution\",\n",
    "        \"east_antarctic_contribution\",\n",
    "    ],\n",
    "    labels=[\"Greenland\", \"West Antarctic\", \"East Antarctic\"],\n",
    "    ncols=3,\n",
    "    uniform_color_scale=False,\n",
    ")\n",
    "\n",
    "print(print_statement)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae119f7",
   "metadata": {},
   "source": [
    "## Error distribution\n",
    "\n",
    "Plotting the error distribution across different segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the error vs frequency histogram for each segment on one axis\n",
    "bins = 40\n",
    "density = True\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for segment in np.unique(error_output[\"segment\"]):\n",
    "    segment_data = error_output[error_output[\"segment\"] == segment]\n",
    "    ax.hist(\n",
    "        segment_data[\"error\"],\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        label=f\"Segment ±{int(segment)}°\",\n",
    "        density=density,\n",
    "        # use Perceptually Uniform Sequential colormap\n",
    "        color=cmap(segment / 90),\n",
    "        align=\"mid\",\n",
    "    )\n",
    "# add a opaque line around each histogram for visibility\n",
    "for segment in np.unique(error_output[\"segment\"]):\n",
    "    segment_data = error_output[error_output[\"segment\"] == segment]\n",
    "    ax.hist(\n",
    "        segment_data[\"error\"],\n",
    "        bins=bins,\n",
    "        density=density,\n",
    "        # use Perceptually Uniform Sequential colormap\n",
    "        color=cmap(segment / 90),\n",
    "        align=\"mid\",\n",
    "        histtype=\"step\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "ax.set_xlabel(\"Error (%)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\n",
    "    \"Sea Level Rise Approximation Error Across Satellite Segments\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "# label the peak of each histogram with its segment\n",
    "for segment in np.unique(error_output[\"segment\"]):\n",
    "    segment_data = error_output[error_output[\"segment\"] == segment]\n",
    "    counts, bin_edges = np.histogram(segment_data[\"error\"], bins=50, density=True)\n",
    "    max_count_index = np.argmax(counts)\n",
    "    peak_error = (bin_edges[max_count_index] + bin_edges[max_count_index + 1]) / 2\n",
    "    ax.text(\n",
    "        peak_error,\n",
    "        counts[max_count_index],\n",
    "        f\"±{int(segment)}°\",\n",
    "        fontsize=9,\n",
    "        fontweight=\"bold\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac36a5a",
   "metadata": {},
   "source": [
    "## Characterising error distribution\n",
    "\n",
    "To better understand the error, model the error distribution for each segment using a various distributions and calculate goodness-of-fit metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c70ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each segment, calculate the log normal distribution parameters of the error\n",
    "log_normal_error_distribution = {}\n",
    "gaussian_error_distribution = {}\n",
    "exponential_error_distribution = {}\n",
    "gamma_error_distribution = {}\n",
    "misfit_log_normal = []\n",
    "misfit_gaussian = []\n",
    "misfit_exponential = []\n",
    "misfit_gamma = []\n",
    "\n",
    "for segment in np.unique(error_output[\"segment\"]):\n",
    "    segment_data = error_output[error_output[\"segment\"] == segment]\n",
    "    # log fit of error data\n",
    "    shape, loc, scale = stats.lognorm.fit(segment_data[\"error\"], floc=0)\n",
    "    log_normal_error_distribution[segment] = {\n",
    "        \"shape\": shape,\n",
    "        \"loc\": loc,\n",
    "        \"scale\": scale,\n",
    "    }\n",
    "    # gaussian fit of error data\n",
    "    mean_error = segment_data[\"error\"].mean()\n",
    "    std_error = segment_data[\"error\"].std()\n",
    "    gaussian_error_distribution[segment] = {\"mean\": mean_error, \"std\": std_error}\n",
    "    # exponential fit of error data\n",
    "    expon = stats.expon.fit(segment_data[\"error\"], floc=0)\n",
    "    exponential_error_distribution[segment] = {\"scale\": expon[1]}\n",
    "    # gamma fit of error data\n",
    "    a, loc, scale = stats.gamma.fit(segment_data[\"error\"], floc=0)\n",
    "    gamma_error_distribution[segment] = {\"a\": a, \"loc\": loc, \"scale\": scale}\n",
    "\n",
    "\n",
    "log_normal_error_distribution = pd.DataFrame(log_normal_error_distribution).T\n",
    "# print(log_normal_error_distribution)\n",
    "gaussian_error_distribution = pd.DataFrame(gaussian_error_distribution).T\n",
    "# print(gaussian_error_distribution)\n",
    "exponential_error_distribution = pd.DataFrame(exponential_error_distribution).T\n",
    "# print(exponential_error_distribution)\n",
    "gamma_error_distribution = pd.DataFrame(gamma_error_distribution).T\n",
    "# print(gamma_error_distribution)\n",
    "\n",
    "\n",
    "for segment in np.unique(error_output[\"segment\"]):\n",
    "    segment_data = error_output[error_output[\"segment\"] == segment]\n",
    "    # empirical histogram\n",
    "    counts, bin_edges = np.histogram(segment_data[\"error\"], bins=50, density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # log normal PDF\n",
    "    shape = log_normal_error_distribution.loc[segment, \"shape\"]\n",
    "    loc = log_normal_error_distribution.loc[segment, \"loc\"]\n",
    "    scale = log_normal_error_distribution.loc[segment, \"scale\"]\n",
    "    pdf_log_normal = stats.lognorm.pdf(bin_centers, shape, loc=loc, scale=scale)\n",
    "\n",
    "    # gaussian PDF\n",
    "    mean = gaussian_error_distribution.loc[segment, \"mean\"]\n",
    "    std = gaussian_error_distribution.loc[segment, \"std\"]\n",
    "    pdf_gaussian = stats.norm.pdf(bin_centers, loc=mean, scale=std)\n",
    "\n",
    "    # exponential PDF\n",
    "    scale_expon = exponential_error_distribution.loc[segment, \"scale\"]\n",
    "    pdf_exponential = stats.expon.pdf(bin_centers, scale=scale_expon)\n",
    "\n",
    "    # gamma PDF\n",
    "    a = gamma_error_distribution.loc[segment, \"a\"]\n",
    "    loc_gm = gamma_error_distribution.loc[segment, \"loc\"]\n",
    "    scale_gm = gamma_error_distribution.loc[segment, \"scale\"]\n",
    "    pdf_gamma = stats.gamma.pdf(bin_centers, a, loc=loc_gm, scale=scale_gm)\n",
    "\n",
    "    # calculate misfit as sum of squared differences\n",
    "    misfit_ln = np.sum((counts - pdf_log_normal) ** 2)\n",
    "    misfit_gs = np.sum((counts - pdf_gaussian) ** 2)\n",
    "    misfit_es = np.sum((counts - pdf_exponential) ** 2)\n",
    "    misfit_gm = np.sum((counts - pdf_gamma) ** 2)\n",
    "\n",
    "    misfit_log_normal.append(misfit_ln)\n",
    "    misfit_gaussian.append(misfit_gs)\n",
    "    misfit_exponential.append(misfit_es)\n",
    "    misfit_gamma.append(misfit_gm)\n",
    "\n",
    "log_normal_error_distribution[\"misfit\"] = misfit_log_normal\n",
    "gaussian_error_distribution[\"misfit\"] = misfit_gaussian\n",
    "exponential_error_distribution[\"misfit\"] = misfit_exponential\n",
    "gamma_error_distribution[\"misfit\"] = misfit_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b976ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subplots for each segment showing empirical histogram and fitted distributions with misfit values in legend\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "nrows = 5\n",
    "ncols = 2\n",
    "\n",
    "for idx, segment in enumerate(np.unique(error_output[\"segment\"])):\n",
    "    ax = fig.add_subplot(nrows, ncols, idx + 1)\n",
    "\n",
    "    segment_data = error_output[error_output[\"segment\"] == segment]\n",
    "    counts, bin_edges, _ = ax.hist(\n",
    "        segment_data[\"error\"],\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        label=\"Empirical\",\n",
    "        density=density,\n",
    "        color=\"gray\",\n",
    "        align=\"mid\",\n",
    "    )\n",
    "\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # log normal PDF\n",
    "    shape = log_normal_error_distribution.loc[segment, \"shape\"]\n",
    "    loc = log_normal_error_distribution.loc[segment, \"loc\"]\n",
    "    scale = log_normal_error_distribution.loc[segment, \"scale\"]\n",
    "    pdf_log_normal = stats.lognorm.pdf(bin_centers, shape, loc=loc, scale=scale)\n",
    "    ax.plot(\n",
    "        bin_centers,\n",
    "        pdf_log_normal,\n",
    "        label=f\"Log-Normal (misfit {log_normal_error_distribution.loc[segment, 'misfit']:.4f})\",\n",
    "        color=\"blue\",\n",
    "    )\n",
    "\n",
    "    # gaussian PDF\n",
    "    mean = gaussian_error_distribution.loc[segment, \"mean\"]\n",
    "    std = gaussian_error_distribution.loc[segment, \"std\"]\n",
    "    pdf_gaussian = stats.norm.pdf(bin_centers, loc=mean, scale=std)\n",
    "    ax.plot(\n",
    "        bin_centers,\n",
    "        pdf_gaussian,\n",
    "        label=f\"Gaussian (misfit {gaussian_error_distribution.loc[segment, 'misfit']:.4f})\",\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "    # exponential PDF\n",
    "    scale_expon = exponential_error_distribution.loc[segment, \"scale\"]\n",
    "    pdf_exponential = stats.expon.pdf(bin_centers, scale=scale_expon)\n",
    "    ax.plot(\n",
    "        bin_centers,\n",
    "        pdf_exponential,\n",
    "        label=f\"Exponential (misfit {exponential_error_distribution.loc[segment, 'misfit']:.4f})\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "\n",
    "    # gamma PDF\n",
    "    a = gamma_error_distribution.loc[segment, \"a\"]\n",
    "    loc_gm = gamma_error_distribution.loc[segment, \"loc\"]\n",
    "    scale_gm = gamma_error_distribution.loc[segment, \"scale\"]\n",
    "    pdf_gamma = stats.gamma.pdf(bin_centers, a, loc=loc_gm, scale=scale_gm)\n",
    "    ax.plot(\n",
    "        bin_centers,\n",
    "        pdf_gamma,\n",
    "        label=f\"Gamma (misfit {gamma_error_distribution.loc[segment, 'misfit']:.4f})\",\n",
    "        color=\"purple\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Error (%)\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.set_title(f\"Segment ±{int(segment)}°\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the misfit values for each distribution vs segment angle with inset plots showing the histogram of each segment without the fitted distributions (location is below the lower x axis label and at each x value that corresponds to the segment angle)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(\n",
    "    log_normal_error_distribution.index,\n",
    "    log_normal_error_distribution[\"misfit\"],\n",
    "    label=\"Log-Normal\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.plot(\n",
    "    gaussian_error_distribution.index,\n",
    "    gaussian_error_distribution[\"misfit\"],\n",
    "    label=\"Gaussian\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.plot(\n",
    "    exponential_error_distribution.index,\n",
    "    exponential_error_distribution[\"misfit\"],\n",
    "    label=\"Exponential\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.plot(\n",
    "    gamma_error_distribution.index,\n",
    "    gamma_error_distribution[\"misfit\"],\n",
    "    label=\"Gamma\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.set_xlabel(\"Segment Angle (°)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Misfit\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\n",
    "    \"Misfit of Fitted Error Distributions Across Satellite Segments\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Get the x-axis limits to properly position insets\n",
    "x_min, x_max = ax.get_xlim()\n",
    "\n",
    "# inset plots\n",
    "for segment in np.unique(error_output[\"segment\"]):\n",
    "    segment_data = error_output[error_output[\"segment\"] == segment]\n",
    "\n",
    "    # Convert segment angle to normalized position (0 to 1) along x-axis\n",
    "    x_pos = (segment - x_min) / (x_max - x_min)\n",
    "\n",
    "    inset_ax = ax.inset_axes(\n",
    "        [\n",
    "            x_pos - 0.05,  # center the inset (subtract half of width)\n",
    "            -0.35,\n",
    "            0.1,\n",
    "            0.2,\n",
    "        ]\n",
    "    )\n",
    "    inset_ax.hist(\n",
    "        segment_data[\"error\"],\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        # label=f\"Segment ±{int(segment)}°\",\n",
    "        density=density,\n",
    "        color=\"gray\",\n",
    "        align=\"mid\",\n",
    "    )\n",
    "    # inset_ax.set_title(f\"±{int(segment)}°\", fontsize=8)\n",
    "    inset_ax.set_xticks([])\n",
    "    inset_ax.set_yticks([])\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
